{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summery\n",
    "1. Reading the files\n",
    "2. Considerations\n",
    "3. Modeling\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Reading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245455, 70)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data_fe.csv')\n",
    "labels = pd.read_csv('../data/machine_learning_challenge_labeled_data.csv')\n",
    "\n",
    "data = df.merge(labels, on='customer_id')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Considerations\n",
    "* `Metric`: As we saw, the data is an imbalance, so picking the metric should be less sensitive to this part(EX. AUC is not the best metric because of that). In the good practical setup, we could use a **cost function** for confusion matrix(EX. what is the cost of losing someone by not detecting them(FP), or what is the cost of sending a voucher to someone is not going to be churn(FN)), But here we don't have that information, we need a metric another metric to look at. Another point is we need to have only one metric to compare things. It's nice to be able to compare models in different ways, but we need to pick one metric. Between **F1** and **average precision**, I chose **average precision** because at the same time we can use precision-recall plots as well.\n",
    "* `Cross-validation`: I split the data into train-test(0.8-0.2) with keeping the ratio of the rare class in both sides. I don't have enough computation power to do k-fold validation, But it's something good to try.\n",
    "* `Categorical Features`: Encoding categorical features can be tricky and it depends on the model. For example Tree based models are not good in handleing the OneHot encoding but Linear models are like it more, On the other hand binnery encoding is a good option for trees. One other way is to replace the feature with it counts. We may lose some infromation becasue of encoding, but it's we have to test and see which works better.\n",
    "* `reproducibility`: I'm using SEED in all of the random part of models, to make them reproducibile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = data.is_returning_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['customer_id', 'is_returning_customer'], axis=1),\n",
    "    data.is_returning_customer,\n",
    "    train_size = 0.8, shuffle= SEED, stratify=labels.is_returning_customer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196364, 68)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
